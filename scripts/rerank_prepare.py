import argparse

import torch
import sentencepiece as spm

COMETSRC_MODEL = "wmt20-comet-qe-da"
COMETSRC_BATCH_SIZE = 64
TRANSQUEST_MODEL = "TransQuest/monotransquest-da-multilingual"
TRANSQUEST_BATCH_SIZE = 64

def read_source_file(source_file_path):
    with open(source_file_path, encoding='utf-8') as source_file:
        # this is a bit dangerous as it reads the whole file into memory
        # it works for experiments with controlled (small) datasets 
        source_lines = [line.strip() for line in source_file.readlines()]
        
    return source_lines


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("hyps", help="file with the hypotheses generated by the MT system")
    parser.add_argument("scores", help="the scores derived from the MT system relative to each hypothesis")
    parser.add_argument("formatted", help="the output file to which the features are going to be saved to")
    # FIXME: why do we need this? it is not being used
    parser.add_argument("--spm", default=False)
    parser.add_argument("--nbest", required=True, type=int)
    parser.add_argument("--add-cometsrc", default=None)
    parser.add_argument("--add-transquest", action="store_true")
    parser.add_argument("--add-openkiwi", default=None, type=str, help="path to the OpenKiwi model")
    parser.add_argument("--comet-path", default=None)
    parser.add_argument("--src", default=None, help="file with the source sentences")
    args = parser.parse_args()

    with open(args.hyps, encoding="utf-8") as hyp_f:
        hyps = [line.strip() for line in hyp_f.readlines()]

    with open(args.scores, encoding="utf-8") as score_f:
        scores = [float(line.strip()) for line in score_f.readlines()]

    def src_hyp_iterator(srcs, hyps):
        assert len(srcs) * args.nbest == len(
            hyps
        ), f"{len(srcs) * args.nbest} != {len(hyps)}"
        for i, src in enumerate(srcs):
            for j in range(args.nbest):
                hyp = hyps[i * args.nbest + j]
                yield src, hyp

    if args.add_cometsrc is not None:
        from comet import download_model, load_from_checkpoint

        assert args.src is not None, "source needs to be provided to use COMET"
        srcs = read_source_file(args.src)

        # download comet and load
        comet_path = download_model(COMETSRC_MODEL, args.add_cometsrc)
        comet_model = load_from_checkpoint(comet_path)
        comet_input = [
            {"src": src, "mt": mt} for src, mt in src_hyp_iterator(srcs, hyps)
        ]
        comet_scores, _ = comet_model.predict(
            comet_input,
            num_workers=4,
            batch_size=COMETSRC_BATCH_SIZE,
            sort_by_mtlen=True,
        )
        torch.cuda.empty_cache()

    if args.add_transquest:
        from transquest.algo.sentence_level.monotransquest.run_model import (
            MonoTransQuestModel,
            MonoTransQuestArgs,
        )

        assert args.src is not None, "source needs to be provided to use Transquest"
        srcs = read_source_file(args.src)

        transquest_args = MonoTransQuestArgs(eval_batch_size=TRANSQUEST_BATCH_SIZE)
        transquest_model = MonoTransQuestModel(
            "xlmroberta",
            TRANSQUEST_MODEL,
            num_labels=1,
            use_cuda=torch.cuda.is_available(),
            args=transquest_args,
        )
        transquest_input = [[src, mt] for src, mt in src_hyp_iterator(srcs, hyps)]
        transquest_scores, _ = transquest_model.predict(transquest_input)
        torch.cuda.empty_cache()

    if args.add_openkiwi:
        assert args.src is not None, "source needs to be provided to use OpenKiwi"
        srcs = read_source_file(args.src)

        from kiwi.lib.predict import load_system

        # prepares input for OpenKiwi        
        openkiwi_source = [src for src, _ in src_hyp_iterator(srcs, hyps)]
        openkiwi_hyps = [tgt for _, tgt in src_hyp_iterator(srcs, hyps)]

        # openkiwi_source = openkiwi_source[0:100]
        # openkiwi_hyps = openkiwi_hyps[0:100]

        runner = load_system(args.add_openkiwi, gpu_id=0)
        # runner = load_system(args.add_openkiwi)

        openkiwi_scores = runner.predict(
            source=openkiwi_source,
            target=openkiwi_hyps,
        )

    with open(args.formatted, "w", encoding='utf-8') as formatted_f:
        for i, (hyp, score) in enumerate(zip(hyps, scores)):
            sample = i // args.nbest
            parts = [str(sample), hyp, f"{score}"]
            features = [f"logprob={score}"]

            if args.add_cometsrc is not None:
                features.append(f"cometsrc={comet_scores[i]}")
    
            if args.add_transquest:
                features.append(f"transquest={transquest_scores[i]}")

            if args.add_openkiwi:
                features.append(f"openkiwi={openkiwi_scores.sentences_hter[i]}")

            parts.append(" ".join(features))
            print(" ||| ".join(parts), file=formatted_f)


if __name__ == "__main__":
    main()
